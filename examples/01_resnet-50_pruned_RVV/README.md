# ResNet-50

In this example, we will demo how to use AITemplate for inference on the ResNet-50 model from PyTorch Image Models (TIMM).

We will demo two usages:
* Using AIT to accelerate PyTorch inference
* Using AIT standalone under RVV environment

## Code structure
```
modeling
    resnet.py              # ResNet definition using AIT's frontend API
weight_utils.py            # Utils to convert TIMM R-50 weights to AIT
infer_with_torch.py        # Example to accelerate PyTorch, and seamlessly use with other PyTorch code
infer_with_numpy.py        # Dump TIMM weights to Numpy and use AIT & Numpy without 3rdparties
benchmark_pt.py            # Benchmark code for PyTorch
benchmark_ait_rvv.py       # Benchmark code for AIT & XNNPACK backend through \
                                sending compiled object files, python scripts to RISC-V board \
                                and retrive the benchmark result from RISC-V board
remote_send_receive_files.py # functions for remote sending/retriving the files
static
    FakeTorchTensor.py     # Fake torch tensor (torch library isn't supported on device)
    model.py               # Python bindings to the AIT runtime on device
    model_utils.py         # utils used in model.py

    run_benchmark_on_riscv.py # not updated yet
    test_correctness_pruning_on_riscv.py # generate the metadata needed by the model and zip the result generated by pytorch to .npz file for the verification in the future
    weight_pruning.py      # perform column-wise pruning
    chosen_lmul_bs{batch_size}.md # record the best choose of lmul for each operator
    model-generated.h      # used to fetch the corresponding operator of each weight
    group_op_and_lmul.py   # group operator and the corresponding lmul based on the content in chosen_lmul_bs{batch_size}.md
    test_correctness_standalone.py # compare the result generated by pytorch and the one generated by AIT in .npz format
```



## Reference Speed vs PyTorch Eager



### Note for Performance Results


